{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial procedures\n",
    "\n",
    "To outline what I did here, I combined the training and testing sets in order to guarantee that whatever automatically-generated features I obtain are trained by the model and will work in predicting (possibly or not possibly well) for the testing set. In a more math-y way of speaking, I'm making sure that the basis vectors are consistent.\n",
    "\n",
    "I separated out and created a lot of features here. I'm guessing that there probably is a much more efficient way of doing all of this, but I think that in order to explain the model well, it's best if I have more control over what I think is important (and later on, I will be verifying that it is or is not important for the model).\n",
    "\n",
    "There's a very trivial procedure to decompose the combined set (the very last lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "\n",
    "folder_path = \"c:/users/jeff/dropbox/kaggleanimalshelter/\"\n",
    "\n",
    "train = pd.read_csv(folder_path + \"train.csv\", encoding='utf-8')\n",
    "test = pd.read_csv(folder_path + \"test.csv\", encoding='utf-8')\n",
    "\n",
    "combined = train.append(test)\n",
    "\n",
    "def cleanFeatures(df):\n",
    "    \n",
    "    # Separate out the sex and if the animal's genitals are intact\n",
    "    df['Male'] = (df['SexuponOutcome'] == u'Intact Male') | (df['SexuponOutcome'] == u'Neutered Male')\n",
    "    df['NeuteredSpayed'] = (df['SexuponOutcome'] == u'Spayed Female') | (df['SexuponOutcome'] == u'Neutered Male')\n",
    "    df['SexuponOutcomeKnown'] = ~df['SexuponOutcome'].isnull()\n",
    "    df = df.drop('SexuponOutcome',1)\n",
    "\n",
    "    # Determine if the animal is a dog or not\n",
    "    df['Dog'] = df['AnimalType'] == u'Dog'\n",
    "    df = df.drop('AnimalType',1)\n",
    "\n",
    "    # Transform each animal's age into a more standard form\n",
    "    # Note: 99999 indicates an unknown age. Of course, it's not\n",
    "    # an actual age, but something to separate the knowns from\n",
    "    # unknowns and effectively \"discretize\" on a continuous spectrum\n",
    "    (df['Age (Weeks)'],df['Units']) = (df['AgeuponOutcome'].str.split(' ', expand=True)[0],\n",
    "                               df['AgeuponOutcome'].str.split(' ', expand=True)[1])\n",
    "    df['Age (Weeks)'] = df['Age (Weeks)'].convert_objects(convert_numeric=True)\n",
    "    df.loc[df['Units'] == 'years','Units'] = 'year'\n",
    "    df.loc[df['Units'] == 'months','Units'] = 'month'\n",
    "    df.loc[df['Units'] == 'weeks','Units'] = 'week'\n",
    "    df.loc[df['Units'] == 'year','Age (Weeks)'] = df.loc[df['Units'] == 'year','Age (Weeks)'] * 52\n",
    "    df.loc[df['Units'] == 'month','Age (Weeks)'] = df.loc[df['Units'] == 'month','Age (Weeks)'] * 4\n",
    "    df.loc[df['Age (Weeks)'].isnull(),'Age (Weeks)'] = 99999\n",
    "    df = df.drop(['AgeuponOutcome','Units'],1)\n",
    "\n",
    "    # New feature: neutered young (less than ~1 year of age)\n",
    "    df['NeuteredYoung'] = (df['Age (Weeks)'].astype(int) < 53 &\n",
    "                           df['NeuteredSpayed'])\n",
    "    \n",
    "    # Separate out the date/time into its individual components\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    df['YearOutcome'] = df['DateTime'].dt.year\n",
    "    df['MonthOutcome'] = df['DateTime'].dt.month\n",
    "    df['DayOutcome'] = df['DateTime'].dt.day\n",
    "    df['HourOutcome'] = df['DateTime'].dt.hour\n",
    "    df['MinuteOutcome'] = df['DateTime'].dt.minute\n",
    "    df['SecondOutcome'] = df['DateTime'].dt.second\n",
    "    df['DayOfWeekOutcome'] = df['DateTime'].dt.dayofweek\n",
    "    df = df.drop('DateTime',1)\n",
    "\n",
    "    # Features from names\n",
    "    df['HasName'] = ~df['Name'].isnull()\n",
    "    df['ShortName'] = df['Name'].str.len() < 5\n",
    "    names = df[~df['Name'].isnull()]['Name']\n",
    "    names_count = names.value_counts().to_frame()\n",
    "    names_list = names_count.index\n",
    "    tolerance_common = 0.005\n",
    "    tolerance_rare = 0.001\n",
    "    df['Common'] = pd.Series()\n",
    "    df['Uncommon'] = pd.Series()\n",
    "    df['Rare'] = pd.Series()\n",
    "        # For animals with unknown names, I'll assume it's equally likely\n",
    "        # for it to take on a name of varying rarity. Really, though,\n",
    "        # it should follow some probability distribution\n",
    "    df.loc[df['Name'].isnull(),'Common'] = True\n",
    "    df.loc[df['Name'].isnull(),'Uncommon'] = True\n",
    "    df.loc[df['Name'].isnull(),'Rare'] = True\n",
    "    names_count['Rarity'] = pd.Series()\n",
    "    names_count.loc[names_count[0L].astype(float) / names.shape[0] > \n",
    "                    tolerance_common,\n",
    "                    'Rarity'] = 0\n",
    "    names_count.loc[(names_count[0L].astype(float) / names.shape[0] <= 0.005) & \n",
    "                    names_count[0L].astype(float) / names.shape[0] > 0.001,\n",
    "                    'Rarity'] = 1\n",
    "    names_count.loc[names_count[0L].astype(float) / names.shape[0] <= 0.001,\n",
    "                    'Rarity'] = 2\n",
    "    for name in names_list:\n",
    "        if names_count['Rarity'][name] == 0:\n",
    "            df.loc[df['Name'] == name,'Common'] = True\n",
    "            df.loc[df['Name'] == name,'Uncommon'] = False\n",
    "            df.loc[df['Name'] == name,'Rare'] = False\n",
    "        elif names_count['Rarity'][name] == 1:\n",
    "            df.loc[df['Name'] == name,'Common'] = False\n",
    "            df.loc[df['Name'] == name,'Uncommon'] = True\n",
    "            df.loc[df['Name'] == name,'Rare'] = False\n",
    "        else:\n",
    "            df.loc[df['Name'] == name,'Common'] = False\n",
    "            df.loc[df['Name'] == name,'Uncommon'] = False\n",
    "            df.loc[df['Name'] == name,'Rare'] = True\n",
    "    df = df.drop('Name',axis=1)\n",
    "\n",
    "    # Features from colors\n",
    "    color_list = []\n",
    "    for color in df['Color'].unique():\n",
    "        new_colors = color.split('/')\n",
    "        for new_color in new_colors:\n",
    "            new_color_list = new_color.split(' ')\n",
    "            for identifier in new_color_list:\n",
    "                if str(identifier) not in color_list:\n",
    "                    color_list.append(str(identifier))\n",
    "    for color in color_list:\n",
    "        df[str(color)] = df['Color'].str.contains(color)\n",
    "    df = df.drop('Color', axis=1)\n",
    "\n",
    "    # There were so many breeds, so I tried my best to categorize based on\n",
    "    # what seemed to be popular and recognizable breeds. Later, I think\n",
    "    # this could be improved by looking a bit more at histograms of these\n",
    "    # various categorizations I created, and more\n",
    "    df['Mixed'] = (df['Breed'].str.contains('Mix') |\n",
    "                   df['Breed'].str.contains('/'))\n",
    "    df['Breed'] = df['Breed'].str.rstrip('Mix').str.rstrip()\n",
    "    df['PitBull'] = df['Breed'].str.contains('Pit Bull')\n",
    "    df['Terrier'] = df['Breed'].str.contains('Terrier')\n",
    "    df['Mini'] = df['Breed'].str.contains('Miniature')\n",
    "    df['Corgi'] = df['Breed'].str.contains('Corgi')\n",
    "    df['Retriever'] = df['Breed'].str.contains('Retriever')\n",
    "    df['Hound'] = df['Breed'].str.contains('Hound')\n",
    "    df['Husky'] = df['Breed'].str.contains('Husky')\n",
    "    df['Beagle'] = df['Breed'].str.contains('Beagle')\n",
    "    df['Chihuahua'] = df['Breed'].str.contains('Chichuahua')\n",
    "    df['Bulldog'] = df['Breed'].str.contains('Bulldog')\n",
    "    df['ShireDog'] = df['Breed'].str.contains('shire')\n",
    "    df['GreatPyrenees'] = df['Breed'].str.contains('Great Pyrenees')\n",
    "    df['Shepherd'] = df['Breed'].str.contains('Shepherd')\n",
    "    df['Dachshund'] = df['Breed'].str.contains('Dachshund')\n",
    "    df['Rottweiler'] = df['Breed'].str.contains('Rottweiler')\n",
    "    df['CatMixed'] = (df['Breed'].str.contains('Domestic Shorthair') |\n",
    "                     df['Breed'].str.contains('Domestic Longhair') |\n",
    "                     df['Breed'].str.contains('Domestic Medium Hair'))\n",
    "    df['ExoticForeignCat'] = ( (df['Dog'] == False) & \n",
    "                       ( df['Breed'].str.contains('Siamese') |\n",
    "                        df['Breed'].str.contains('Himalayan') |\n",
    "                        df['Breed'].str.contains('Persian') |\n",
    "                        df['Breed'].str.contains('Angora') |\n",
    "                        df['Breed'].str.contains('Bombay') |\n",
    "                        df['Breed'].str.contains('Japanese') |\n",
    "                        df['Breed'].str.contains('Bengal') |\n",
    "                        df['Breed'].str.contains('Cymric') |\n",
    "                        df['Breed'].str.contains('Abyssinian') |\n",
    "                        df['Breed'].str.contains('Sphynx') |\n",
    "                        df['Breed'].str.contains('Javanese') |\n",
    "                        df['Breed'].str.contains('Turkish') |\n",
    "                        df['Breed'].str.contains('Chartreaux') |\n",
    "                        df['Breed'].str.contains('Norwegian') |\n",
    "                        df['Breed'].str.contains('Russian') ) )\n",
    "    df['MaineCoon'] = df['Breed'].str.contains('Maine Coon')\n",
    "    df['Shorthair'] = df['Breed'].str.contains('Shorthair')\n",
    "    df['Longhair'] = df['Breed'].str.contains('Longhair')\n",
    "    df['Ragdoll'] = df['Breed'].str.contains('Ragdoll')\n",
    "    df['American'] = df['Breed'].str.contains('American')\n",
    "    df['Australian'] = df['Breed'].str.contains('Australian')\n",
    "    df['German'] = df['Breed'].str.contains('German')\n",
    "    df['Japanese'] = df['Breed'].str.contains('Japanese')\n",
    "    df['Munchkin'] = df['Breed'].str.contains('Munchkin')\n",
    "    df['RexCat'] = df['Breed'].str.contains('Rex')\n",
    "    df['ColdWeather'] = (df['Breed'].str.contains('Siberian') |\n",
    "                         df['Breed'].str.contains('Russian') |\n",
    "                         df['Breed'].str.contains('Longhair') |\n",
    "                         df['Breed'].str.contains('Norwegian'))\n",
    "    df = df.drop('Breed',axis=1)\n",
    "\n",
    "    # This is actually not useful because these are usually just comments\n",
    "    # on the outcome\n",
    "    if 'OutcomeSubtype' in df.columns:\n",
    "        df = df.drop('OutcomeSubtype',axis=1)\n",
    "        \n",
    "    return df\n",
    "\n",
    "combined = cleanFeatures(combined)\n",
    "\n",
    "train_cleaned = combined[combined['ID'].isnull()].drop(['ID'],axis=1)\n",
    "test_cleaned = combined[combined['AnimalID'].isnull()].drop(['AnimalID'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to save the cleaned data so I don't have to run all the functions to get cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cleaned.to_csv('c:/users/jeff/dropbox/kaggleanimalshelter/traincleaned.csv',index=False)\n",
    "test_cleaned.to_csv('c:/users/jeff/dropbox/kaggleanimalshelter/testcleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_RFC(train_X, train_y, test_X):\n",
    "    rf = RandomForestClassifier(n_estimators=250, max_depth=None, \n",
    "                                min_samples_split=1)\n",
    "    rf.fit(train_X, train_y)\n",
    "    predictions = rf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_cleaned['OutcomeType']\n",
    "train_X = train_cleaned.drop(['OutcomeType','AnimalID'],axis=1)\n",
    "test_X = test_cleaned.drop(['ID','OutcomeType'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_drop = [\n",
    "    [],\n",
    "    ['Common','Uncommon','Rare'],\n",
    "    ['MinuteOutcome','SecondOutcome'],\n",
    "    \n",
    "]\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(list_drop)):\n",
    "\n",
    "    cf_train_X, cf_test_X, cf_y_train, cf_y_test = cross_validation.train_test_split(\n",
    "        train_X.drop(list_drop[i],axis=1), train_y, test_size=0.25, random_state=0)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=50, max_depth=None, min_samples_split=1)\n",
    "    rf.fit(cf_train_X, cf_y_train)\n",
    "    x.append(i)\n",
    "    y.append(rf.score(cf_test_X, cf_y_test))\n",
    "\n",
    "sample_split = pd.DataFrame()\n",
    "sample_split['list_dropped'] = x\n",
    "sample_split['Accuracy'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['ID','Adoption','Died','Euthanasia','Return_to_owner','Transfer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for outcome in range(predictions.shape[1]): \n",
    "    \n",
    "    new_list = []\n",
    "\n",
    "    for row in range(predictions.shape[0]):\n",
    "        new_list.append(predictions[row][outcome])\n",
    "        \n",
    "    output_df[headers[1+outcome]] = new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df['ID'] = test_cleaned['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv(folder_path + 'predicted.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
