{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial procedures\n",
    "\n",
    "To outline what I did here, I combined the training and testing sets in order to guarantee that whatever automatically-generated features I obtain are trained by the model and will work in predicting (possibly or not possibly well) for the testing set. In a more math-y way of speaking, I'm making sure that the basis vectors are consistent.\n",
    "\n",
    "I separated out and created a lot of features here. I'm guessing that there probably is a much more efficient way of doing all of this, but I think that in order to explain the model well, it's best if I have more control over what I think is important (and later on, I will be verifying that it is or is not important for the model).\n",
    "\n",
    "There's a very trivial procedure to decompose the combined set (the very last lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:34: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "folder_path = '/home/pbnjeff/Dropbox/KaggleAnimalShelter/'\n",
    "combined_cleaned_path = '/home/pbnjeff/Dropbox/KaggleAnimalShelter/combined_cleaned.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(folder_path + \"train.csv\", encoding='utf-8')\n",
    "test = pd.read_csv(folder_path + \"test.csv\", encoding='utf-8')\n",
    "combined = train.append(test)\n",
    "\n",
    "def cleanFeatures(df):\n",
    "    \n",
    "    # Separate out the sex and if the animal's genitals are intact\n",
    "    df['Male'] = (df['SexuponOutcome'] == u'Intact Male') | (df['SexuponOutcome'] == u'Neutered Male')\n",
    "    df['NeuteredSpayed'] = (df['SexuponOutcome'] == u'Spayed Female') | (df['SexuponOutcome'] == u'Neutered Male')\n",
    "    df['SexuponOutcomeKnown'] = ~df['SexuponOutcome'].isnull()\n",
    "    df = df.drop('SexuponOutcome',1)\n",
    "\n",
    "    # Determine if the animal is a dog or not\n",
    "    df['Dog'] = df['AnimalType'] == u'Dog'\n",
    "    df = df.drop('AnimalType',1)\n",
    "\n",
    "    # Transform each animal's age into a more standard form\n",
    "    # Note: 99999 indicates an unknown age. Of course, it's not\n",
    "    # an actual age, but something to separate the knowns from\n",
    "    # unknowns and effectively \"discretize\" on a continuous spectrum\n",
    "    (df['Age (Weeks)'],df['Units']) = (df['AgeuponOutcome'].str.split(' ', expand=True)[0],\n",
    "                               df['AgeuponOutcome'].str.split(' ', expand=True)[1])\n",
    "    df['Age (Weeks)'] = df['Age (Weeks)'].convert_objects(convert_numeric=True)\n",
    "    df.loc[df['Units'] == 'years','Units'] = 'year'\n",
    "    df.loc[df['Units'] == 'months','Units'] = 'month'\n",
    "    df.loc[df['Units'] == 'weeks','Units'] = 'week'\n",
    "    df.loc[df['Units'] == 'year','Age (Weeks)'] = df.loc[df['Units'] == 'year','Age (Weeks)'] * 52\n",
    "    df.loc[df['Units'] == 'month','Age (Weeks)'] = df.loc[df['Units'] == 'month','Age (Weeks)'] * 4\n",
    "    df.loc[df['Age (Weeks)'].isnull(),'Age (Weeks)'] = 99999\n",
    "    df = df.drop(['AgeuponOutcome','Units'],1)\n",
    "\n",
    "    # New feature: neutered young (less than ~1 year of age)\n",
    "    # df['NeuteredYoung'] = (df['Age (Weeks)'].astype(int) < 53 & df['NeuteredSpayed'])\n",
    "    \n",
    "    # Separate out the date/time into its individual components\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    # df['YearOutcome'] = df['DateTime'].dt.year\n",
    "    # df['MonthOutcome'] = df['DateTime'].dt.month\n",
    "    # df['DayOfWeekOutcome'] = df['DateTime'].dt.dayofweek\n",
    "    df = df.drop('DateTime',1)\n",
    "\n",
    "    # Features from names\n",
    "    df['HasName'] = ~df['Name'].isnull()\n",
    "    df = df.drop('Name',axis=1)\n",
    "\n",
    "    # Features from colors\n",
    "    color_list = []\n",
    "    #for color in df['Color'].unique():\n",
    "    #    new_colors = color.split('/')\n",
    "    #    for new_color in new_colors:\n",
    "    #        new_color_list = new_color.split(' ')\n",
    "    #        for identifier in new_color_list:\n",
    "    #            if str(identifier) not in color_list:\n",
    "    #                color_list.append(str(identifier))\n",
    "    #for color in color_list:\n",
    "    #    df[str(color)] = df['Color'].str.contains(color)\n",
    "    df = df.drop('Color', axis=1)\n",
    "\n",
    "    # There were so many breeds, so I tried my best to categorize based on\n",
    "    # what seemed to be popular and recognizable breeds. Later, I think\n",
    "    # this could be improved by looking a bit more at histograms of these\n",
    "    # various categorizations I created, and more\n",
    "    #df['Mixed'] = (df['Breed'].str.contains('Mix') |\n",
    "    #               df['Breed'].str.contains('/'))\n",
    "    #df['Breed'] = df['Breed'].str.rstrip('Mix').str.rstrip()\n",
    "    #df['PitBull'] = df['Breed'].str.contains('Pit Bull')\n",
    "    #df['Terrier'] = df['Breed'].str.contains('Terrier')\n",
    "    #df['Mini'] = df['Breed'].str.contains('Miniature')\n",
    "    #df['Corgi'] = df['Breed'].str.contains('Corgi')\n",
    "    #df['Retriever'] = df['Breed'].str.contains('Retriever')\n",
    "    #df['Hound'] = df['Breed'].str.contains('Hound')\n",
    "    #df['Husky'] = df['Breed'].str.contains('Husky')\n",
    "    #df['Beagle'] = df['Breed'].str.contains('Beagle')\n",
    "    #df['Chihuahua'] = df['Breed'].str.contains('Chichuahua')\n",
    "    #df['Bulldog'] = df['Breed'].str.contains('Bulldog')\n",
    "    #df['ShireDog'] = df['Breed'].str.contains('shire')\n",
    "    #df['GreatPyrenees'] = df['Breed'].str.contains('Great Pyrenees')\n",
    "    #df['Shepherd'] = df['Breed'].str.contains('Shepherd')\n",
    "    #df['Dachshund'] = df['Breed'].str.contains('Dachshund')\n",
    "    #df['Rottweiler'] = df['Breed'].str.contains('Rottweiler')\n",
    "    #df['CatMixed'] = (df['Breed'].str.contains('Domestic Shorthair') |\n",
    "    #                 df['Breed'].str.contains('Domestic Longhair') |\n",
    "    #                 df['Breed'].str.contains('Domestic Medium Hair'))\n",
    "    #df['ExoticForeignCat'] = ( (df['Dog'] == False) & \n",
    "    #                   ( df['Breed'].str.contains('Siamese') |\n",
    "    #                    df['Breed'].str.contains('Himalayan') |\n",
    "    #                    df['Breed'].str.contains('Persian') |\n",
    "    #                    df['Breed'].str.contains('Angora') |\n",
    "    #                    df['Breed'].str.contains('Bombay') |\n",
    "    #                    df['Breed'].str.contains('Japanese') |\n",
    "    #                    df['Breed'].str.contains('Bengal') |\n",
    "    #                    df['Breed'].str.contains('Cymric') |\n",
    "    #                    df['Breed'].str.contains('Abyssinian') |\n",
    "    #                    df['Breed'].str.contains('Sphynx') |\n",
    "    #                    df['Breed'].str.contains('Javanese') |\n",
    "    #                    df['Breed'].str.contains('Turkish') |\n",
    "    #                    df['Breed'].str.contains('Chartreaux') |\n",
    "    #                    df['Breed'].str.contains('Norwegian') |\n",
    "    #                    df['Breed'].str.contains('Russian') ) )\n",
    "    #df['MaineCoon'] = df['Breed'].str.contains('Maine Coon')\n",
    "    #df['Shorthair'] = df['Breed'].str.contains('Shorthair')\n",
    "    #df['Longhair'] = df['Breed'].str.contains('Longhair')\n",
    "    #df['Ragdoll'] = df['Breed'].str.contains('Ragdoll')\n",
    "    #df['American'] = df['Breed'].str.contains('American')\n",
    "    #df['Australian'] = df['Breed'].str.contains('Australian')\n",
    "    #df['German'] = df['Breed'].str.contains('German')\n",
    "    #df['Japanese'] = df['Breed'].str.contains('Japanese')\n",
    "    #df['Munchkin'] = df['Breed'].str.contains('Munchkin')\n",
    "    #df['RexCat'] = df['Breed'].str.contains('Rex')\n",
    "    #df['ColdWeather'] = (df['Breed'].str.contains('Siberian') |\n",
    "    #                     df['Breed'].str.contains('Russian') |\n",
    "    #                     df['Breed'].str.contains('Longhair') |\n",
    "    #                     df['Breed'].str.contains('Norwegian'))\n",
    "    df = df.drop('Breed',axis=1)\n",
    "\n",
    "    # This is actually not useful because these are usually just comments\n",
    "    # on the outcome\n",
    "    if 'OutcomeSubtype' in df.columns:\n",
    "        df = df.drop('OutcomeSubtype',axis=1)\n",
    "        \n",
    "    return df\n",
    "\n",
    "combined = cleanFeatures(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([           u'AnimalID',                  u'ID',         u'OutcomeType',\n",
       "                      u'Male',      u'NeuteredSpayed', u'SexuponOutcomeKnown',\n",
       "                       u'Dog',         u'Age (Weeks)',             u'HasName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = combined.columns\n",
    "\n",
    "for feature in features:\n",
    "    if (combined[feature].dtype == 'bool') | (combined[feature].dtype == 'object'):\n",
    "        combined[feature] = combined[feature].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cleaned = combined[combined['ID'].isnull()].drop(['ID'],axis=1)\n",
    "test_cleaned = combined[combined['AnimalID'].isnull()].drop(['AnimalID'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to save the cleaned data so I don't have to run all the functions to get cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cleaned.to_csv('/home/pbnjeff/Dropbox/KaggleAnimalShelter/traincleaned.csv',index=False)\n",
    "test_cleaned.to_csv('/home/pbnjeff/Dropbox/KaggleAnimalShelter/testcleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_cleaned['OutcomeType']\n",
    "train_X = train_cleaned.drop(['OutcomeType','AnimalID'],axis=1)\n",
    "test_X = test_cleaned.drop(['ID','OutcomeType'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = train_X.columns\n",
    "\n",
    "for feature in features:\n",
    "    if (train_X[feature].dtype == 'bool') | (train_X[feature].dtype == 'object'):\n",
    "        train_X[feature] = train_X[feature].astype(int)\n",
    "        test_X[feature] = test_X[feature].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ages_known = train_cleaned[train_cleaned['Age (Weeks)'] < 90000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ages_unknown = train_cleaned[train_cleaned['Age (Weeks)'] == 99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcomes = train_y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = pd.DataFrame(train_cleaned['OutcomeType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcomes = train_y['OutcomeType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in train_X.columns:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for outcome in outcomes:\n",
    "    \n",
    "    train_y[str(outcome)] = pd.Series(data=[0] * train_y.shape[0])\n",
    "    train_y.loc[train_y['OutcomeType'] == str(outcome), str(outcome)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train_y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train_y.drop('OutcomeType', axis = 1)\n",
    "\n",
    "features = train_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_X = train_X[['Male','NeuteredSpayed','SexuponOutcomeKnown','Dog','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_X_test = test_X[['Male','NeuteredSpayed','SexuponOutcomeKnown','Dog','Age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, train_X.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, shape=[None, train_y.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([train_X.shape[1],train_y.shape[1]]))\n",
    "b = tf.Variable(tf.zeros([train_y.shape[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.25).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "\n",
    "while start < short_X.shape[0]:\n",
    "    end = start + 500\n",
    "    if end > train_X.shape[0]:\n",
    "        end = train_X.shape[0]\n",
    "    batch_x = train_X[start:end]\n",
    "    batch_y = train_y[start:end]\n",
    "    train_step.run(feed_dict={x: batch_x, y_: batch_y})\n",
    "    start += 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.179056\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: train_X, y_:train_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict = {x: test_X}\n",
    "classification = sess.run(tf.argmax(y,1), feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['ID','Adoption','Died','Euthanasia','Return_to_owner','Transfer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for outcome in range(predictions.shape[1]): \n",
    "    \n",
    "    new_list = []\n",
    "\n",
    "    for row in range(predictions.shape[0]):\n",
    "        new_list.append(predictions[row][outcome])\n",
    "        \n",
    "    output_df[headers[1+outcome]] = new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df['ID'] = test_cleaned['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv(folder_path + 'predicted.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
